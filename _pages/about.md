---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Hello! I am a third-year Ph.D. student at Harvard, advised by [Flavio du Pin Calmon](http://people.seas.harvard.edu/~flavio/). I completed my undergraduate degree in Math and Computer Science at [NYU Courant](https://cims.nyu.edu/dynamic/) and I interned at [Meta](https://about.meta.com). 

My research interest lies in **Responsible Machine Learning**, which includes fairness, privacy, and interpretability. I contemplate the impacts of ML algorithms on various domains of society for different (exponentially-many) groups of people. I'm currently working on Algorithmic Fairness using tools and frameworks from Information Theory. Feel free to reach out if you would like to discuss! 

# Publications
- [Individual Arbitrariness and Group Fairness](https://openreview.net/pdf?id=nzkWhoXUpv)\
**Carol Xuan Long**, Hsiang Hsu\*, Wael Alghamdi\*, Flavio P Calmon\
Advances in Neural Information Processing Systems (**NeurIPS**), 2023, <span style="color:red">**Spotlight Paper**</span>.\
*TL/DR:* Fairness interventions in machine learning optimized solely for group fairness and accuracy can exacerbate predictive multiplicity. A third axis of ``arbitrariness'' should be considered when deploying models to aid decision-making in applications of individual-level impact. 

<pre><code>
@inproceedings{long2023individual,
  title={Individual Arbitrariness and Group Fairness},
  author={Long, Carol Xuan and Hsu, Hsiang and Alghamdi, Wael and Calmon, Flavio},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}</code></pre>

- [On the epistemic limits of personalized prediction](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DGQASc8AAAAJ&citation_for_view=DGQASc8AAAAJ:d1gkVwhDpl0C)\
Lucas Monteiro Paes\*, **Carol Long**\*, Berk Ustun, Flavio Calmon (* Equal Contribution)\
Advances in Neural Information Processing Systems (**NeurIPS**), 2022\
*TL/DR:* It is impossible to reliably verify that a personalized classifier with $k \geq 19$ binary group attributes will benefit every group that provides personal data using a dataset of $n = 8 × 10^9$ samples – one for each person in the world.

<pre><code>
@article{monteiro2022epistemic,
  title={On the epistemic limits of personalized prediction},
  author={Monteiro Paes, Lucas and Long, Carol and Ustun, Berk and Calmon, Flavio},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1979--1991},
  year={2022}
}</code></pre>

# Misc
Outside of work, being a pianist and dancer, I have a deep appreciation for all art forms, esp. classical music and ballet/contemporary dance. Growing up as a swimmer, I enjoy sports. From completing a half-marathon and recovering from an ACL injury, for better or worse, I do have many stories to tell. Of course, I love cooking Chinese/Singaporean food and reading away (AntiFragile is my recent favorite!) in the comfort of home! 