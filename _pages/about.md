---
permalink: /
title: "Carol Long"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a third-year Ph.D. student in Applied Math at Harvard University, advised by [Flavio du Pin Calmon](http://people.seas.harvard.edu/~flavio/). I completed my undergraduate degree in Math and Computer Science at [the Courant Institute of Mathematical Sciences](https://cims.nyu.edu/dynamic/), New York University, and I interned at [Meta](https://about.meta.com). 

My research interest lies in Responsible Machine Learning, which includes fairness, privacy, and interpretability. I contemplate the impacts of ML algorithms on various domains of the society for different (exponentially-many) groups of people. I'm currently working on Algorithmic Fairness using tools and frameworks from Information Theory. Feel free to reach out if you would like to discuss! 

Outside of work, I train for my to-be-confirmed half-marathon, play a bit of piano, dance ballet/contemp at nearby studios, or simply cooking Chinese/Singaporean food and read (AntiFragile is my recent favorite!) from my cozy home, provided that I am not traveling or planning for a travel. 

## Publications
[Arbitrariness Lies Beyond the Fairness-Accuracy Frontier](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DGQASc8AAAAJ&citation_for_view=DGQASc8AAAAJ:9yKSN-GCB0IC)
**Carol Xuan Long**, Hsiang Hsu*, Wael Alghamdi*, Flavio P Calmon
preprint
Fairness interventions in machine learning optimized solely for group fairness and accuracy can exacerbate predictive multiplicity. A third axis of ``arbitrariness'' should be considered when deploying models to aid decision-making in applications of individual-level impact. 

[On the epistemic limits of personalized prediction](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DGQASc8AAAAJ&citation_for_view=DGQASc8AAAAJ:d1gkVwhDpl0C)
Lucas Monteiro Paes*, **Carol Long***, Berk Ustun, Flavio Calmon (* Equal Contribution)
Neurips, 2023
It is impossible to reliably verify that a personalized classifier with k ≥ 19 binary group attributes will benefit every group who provides personal data using a dataset of n = 8 × 10^9 samples – one for each person in the world.

======