---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a third-year Ph.D. student at Harvard, advised by [Flavio du Pin Calmon](http://people.seas.harvard.edu/~flavio/). I completed my undergraduate degree in Math and Computer Science at [NYU Courant](https://cims.nyu.edu/dynamic/) and I interned at [Meta](https://about.meta.com). I am **looking for an internship for Summer 24'** (open to opportunities in the US, Europe, and Singapore)! 

My research interest lies in **Responsible Machine Learning**, which includes fairness, privacy, and interpretability. I contemplate the impacts of ML algorithms on various domains of society for different (exponentially-many) groups of people. I'm currently working on Algorithmic Fairness using tools and frameworks from Information Theory. Feel free to reach out if you would like to discuss! 

Outside of work, I play a bit of piano, train for my to-be-confirmed half-marathon, dance ballet/contemp at nearby studios, or simply cook Chinese/Singaporean food and read away (AntiFragile is my recent favorite!) in the comfort of home, provided that I am not traveling.

# Publications
- [Arbitrariness Lies Beyond the Fairness-Accuracy Frontier](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DGQASc8AAAAJ&citation_for_view=DGQASc8AAAAJ:9yKSN-GCB0IC)\
**Carol Xuan Long**, Hsiang Hsu\*, Wael Alghamdi\*, Flavio P Calmon\
preprint\
Fairness interventions in machine learning optimized solely for group fairness and accuracy can exacerbate predictive multiplicity. A third axis of ``arbitrariness'' should be considered when deploying models to aid decision-making in applications of individual-level impact. 

- [On the epistemic limits of personalized prediction](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DGQASc8AAAAJ&citation_for_view=DGQASc8AAAAJ:d1gkVwhDpl0C)\
Lucas Monteiro Paes\*, **Carol Long**\*, Berk Ustun, Flavio Calmon (* Equal Contribution)\
Neurips, 2023\
It is impossible to reliably verify that a personalized classifier with $k \geq 19$ binary group attributes will benefit every group that provides personal data using a dataset of $n = 8 × 10^9$ samples – one for each person in the world.

======